{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting input data and some initial values\n",
    "1. 利用 sc.textFile去取得input data 存放於data RDD\n",
    "2. N = 10876代表全部參與network的所有nodes數量\n",
    "3. Beta B = 0.8\n",
    "4. add_val = 1-Beta = 0.2\n",
    "5. complment用於之後考慮dead_ends所得到的回補值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial\n",
    "import time\n",
    "import os\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc.stop()\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"PageRank\")\n",
    "conf=SparkConf().set(\"spark.default.parallelism\", 4)\n",
    "sc = SparkContext(conf = conf)\n",
    "data = sc.textFile(\"p2p-Gnutella04.txt\")\n",
    "N = 10876\n",
    "B = 0.8\n",
    "add_val = (1-B)\n",
    "complement = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the nodes which has receives from other nodes\n",
    "1. 取得data後，利用mapper1取得所有links，並用兩次map與distinct取得所有參與這network的所nodes\n",
    "2. 利用gruopByKey()與mapper2建立一RDD links_with_n，其<key,value>: key = node_i, value = (所有receiver_node pointed by node_i)\n",
    "3. 另外在map中我用1跟-1來標記該node是sender還是receiver，在用reduce1加總來分辨該node的行為如果>=1則代表該node單純只有做sending的動作， 並把那些nodes紀錄於only_sending_nodes RDD\n",
    "4. 創建ranks，並利用initial_ranks_mapper賦予個個key初值 = 1/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct before iteration\n",
    "def mapper1(x):\n",
    "    y = x.split('\\t')\n",
    "    return y[0],y[1]\n",
    "def mapper2(x):\n",
    "    k = []\n",
    "    for i in x[1]:\n",
    "        k.append(i)\n",
    "    return x[0],(k,len(x[1]))\n",
    "def initial_ranks_mapper(x):\n",
    "    return x,1/N\n",
    "def reducer1(x,y):\n",
    "    return x+y\n",
    "def mapper0(x):\n",
    "    if x[1]==0: return x[0]\n",
    "links = data.map(mapper1)\n",
    "links_with_n = links.groupByKey().map(mapper2)\n",
    "rec_node1 = links.map(lambda x:(x[0],1)).distinct() #send nodes\n",
    "rec_node2 = links.map(lambda x:(x[1],-1)).distinct() # rec nodes\n",
    "rec_node = rec_node1.union(rec_node2).map(lambda x:x[0]).distinct()\n",
    "only_sending_nodes = rec_node1.union(rec_node2).reduceByKey(reducer1).filter(lambda x:x[1]>=1)\n",
    "ranks = rec_node.map(initial_ranks_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### considering the nodes that only do sending\n",
    "1. 利用flatMap得到rec_ndoes_all，<key,value>: key:node   values:(對應到的一個contributor,該contribitor貢獻給多少nodes的總數)\n",
    "2. 為了確保為了確保之後在中，每次join後，每個nodes都存在，以免在做回補complement時不會漏加，我利用#當作一個node，讓他指向所有單純sending的nodes，並賦予#這個node的probability = 0 ranks中。\n",
    "3. 有了步驟1的前置動作，才能將那些only-do-sending nodes 加入rec_nodes_all中\n",
    "4. 我認為這樣的好處是可以避免在每在iterarion中還要另外檢查，使得iteration中少了不少步驟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exc_map(x):\n",
    "    return '#',(x[0],1)\n",
    "ex = sc.parallelize(list('#')).map(lambda x:('#',(x,1)))\n",
    "exc = sc.parallelize(list('#')).map(lambda x:(x,0)) #for only sending nodes\n",
    "only_sending_nodes_ex = only_sending_nodes.map(exc_map).union(ex)\n",
    "rec_nodes_all = links_with_n.flatMap(lambda x:[(x[0],(i,x[1][1])) for i in x[1][0]])\n",
    "ranks = ranks.union(exc)\n",
    "rec_nodes_all = rec_nodes_all.union(only_sending_nodes_ex)\n",
    "#rec_nodes_all.cache().collect() # trigger action to cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate in Iteration\n",
    "1. 有了前置準備後，先將rec_nodes_all 與 ranks做join，做出每個receives node所對應到的sending node的rank值\n",
    "2. 再來先用mapper5做map，算出每個receives node所對應到的sending node的contribution 並乘上Beta\n",
    "3. 然後再利用reducer1 將同樣key的value全部加起來，以完成下圖算式:\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/pd1KYQJ/1.jpg\" alt=\"1\" border=\"0\" /></a>\n",
    "4. 接下我們要求未考慮dead_ends的ranks sum，利用map先單純取出value，並用sum()將所有值加總，並加上(1-Beta)/N\n",
    "5. 得到r_sum後，就可以求出考慮dead_ends所需分配回去的complement = (1-r_sum)/N\n",
    "6. 算出complement後，將前面求得的ranks，加上complments與(1-Beta/N)，得到新的ranks已完成一次iteration\n",
    "<a href=\"https://imgbb.com/\"><img src=\"https://i.ibb.co/P9J0GDF/image.jpg\" alt=\"image\" border=\"0\" /></a>\n",
    "<a href=\"https://ibb.co/zhpHvLq\"><img src=\"https://i.ibb.co/WWZpJdm/3.jpg\" alt=\"3\" border=\"0\" /></a>\n",
    "7. 為了減少map量，我是最後才將(1-Beta)/N的值與complement一起加回ranks\n",
    "8. 另外，過程會用到#是對那些單純只有sending的nodes做標記，讓他們在join完後仍存在於RDD中，並再回加complents與(1-Beta)/N時還存在ranks中\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mapper4(x):\n",
    "    if x[0]=='#':\n",
    "        return x[0],0\n",
    "    else: \n",
    "        return x[0],x[1]+complement+(add_val/N)\n",
    "def mapper5(x):\n",
    "    if x[1][0][0]=='#':\n",
    "        return x[1][0][0],0\n",
    "    else: \n",
    "        return x[1][0][0],x[1][1]/x[1][0][1]*B\n",
    "tStart = time.time()\n",
    "for i in range(20):\n",
    "    #print(\"iteration:\"+str(i)+\"...\")\n",
    "    a = rec_nodes_all.join(ranks)\n",
    "    b = a.map(mapper5).reduceByKey(reducer1)\n",
    "    r_sum = b.map(lambda x:x[1]).sum() + add_val\n",
    "    complement = (1-r_sum)/N\n",
    "    ranks = b.map(mapper4)\n",
    "    #print(\"iteration:\"+str(i)+\" end\")\n",
    "    #print(r_sum)\n",
    "tEnd = time.time()#計時結束\n",
    "#print(\"It cost %f sec\" % (tEnd - tStart))\n",
    "#大約15 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting and Output\n",
    "1. 經過20次iteration後，利用sortBy()依據ranks值將結果由大到小排序。\n",
    "2. 將排序結果利用collect()並將前10個pairs output出來。\n",
    "3. 其中'%.3g '代表取小數點後有效的三位。\n",
    "4. final output:\n",
    "```\n",
    "1056\t0.000632 \n",
    "1054\t0.000629 \n",
    "1536\t0.000524 \n",
    "171\t0.000512 \n",
    "453\t0.000496 \n",
    "407\t0.000485 \n",
    "263\t0.00048 \n",
    "4664\t0.00047 \n",
    "261\t0.000463 \n",
    "410\t0.000462\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\t0.000632 \n",
      "1054\t0.000629 \n",
      "1536\t0.000524 \n",
      "171\t0.000512 \n",
      "453\t0.000496 \n",
      "407\t0.000485 \n",
      "263\t0.00048 \n",
      "4664\t0.00047 \n",
      "261\t0.000463 \n",
      "410\t0.000462 \n"
     ]
    }
   ],
   "source": [
    "#print(\"sorting...\")\n",
    "sorted_result_rdd = ranks.sortBy(lambda x:x[1],ascending=False)\n",
    "#print top 10 pairs\n",
    "#print(\"output..\")\n",
    "cnt = 0\n",
    "for i in sorted_result_rdd.collect():\n",
    "    if(cnt<10):\n",
    "        print(i[0]+'\\t'+('%.3g ' % i[1]))\n",
    "    else:\n",
    "        break;\n",
    "    cnt+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term_Project - Recommendation System\n",
    "## Initial and Set config\n",
    "### 結果共用連結: https://drive.google.com/drive/folders/1d_FzC6vwwCdwkUU9hfPHk3blut6E6xq2?usp=sharing\n",
    "#### 兩題共約20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial\n",
    "import math\n",
    "import os\n",
    "from pyspark import StorageLevel\n",
    "import time\n",
    "from pyspark import SparkContext, SparkConf\n",
    "sc.stop()\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Recommendation System\")\n",
    "conf = SparkConf().set(\"spark.default.parallelism\",8)\\\n",
    "    .set('spark.driver.memory', '12G') \\\n",
    "    .set('spark.driver.maxResultSize', '100G')\\\n",
    "    .set('spark.memory.fraction',0.9)\\\n",
    "    .set(\"spark.hadoop.validateOutputSpecs\", \"False\")\\\n",
    "    .set(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\\\n",
    "    .set(\"spark.kryoserializer.buffer.max\",'2000m')\n",
    "    #.set(\"spark.executor.instances\", 4)\\\n",
    "    #.set(\"spark.executor.cores\", 4)\n",
    "    #.set('spark.executor.cores',4) \\\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input data\n",
    "1. 利用sc.textFile()取得資料夾內ratings.csv\n",
    "2. 使用filter 將 header 那一列去掉\n",
    "3. 之後使用map function getNecesssary()來將每個line依據逗號切分，並重新排列順序形成一以movie id為key, (user, rating)為value 的 RDD\n",
    "4. 再來利用groupByKey()來將相同movie id的line合併再一起，形成一以movie id 為key, 所有有評分該movie的(user,rateing)為values的RDD\n",
    "\n",
    "## Input Data\n",
    "1. 取自https://grouplens.org/datasets/movielens/\n",
    "2. format: (userID, movieID, rating)\n",
    "3. 以解壓縮，放在ml-latest-small/ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datas = sc.textFile(\"ml-latest-small/ratings.csv\").filter(lambda x:x[0]!='u')\n",
    "# = sc.textFile(\"ml-latest-small/movies.csv\").filter(lambda x:x[0]!='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing all_movie 47448411\n",
    "def get_movie_id(x):\n",
    "    lines = x.split(',')\n",
    "    id_ = int(lines[0])\n",
    "    return id_,[]\n",
    "#parsing => rdd -> (movie,[(user,rating),(user,rating)..])\n",
    "def getNecesssary(x):\n",
    "    line = x.split(',')\n",
    "    user = str(line[0])\n",
    "    movie = int(line[1])\n",
    "    rating = float(line[2])\n",
    "    \n",
    "    pair = (user, rating)\n",
    "    return movie,pair\n",
    "#All_movies = all_movies.map(get_movie_id)\n",
    "Datas = datas.map(getNecesssary)\n",
    "simple_Items_RDD = Datas.groupByKey().map(lambda x:(x[0],list(x[1]))).persist(StorageLevel.DISK_ONLY).sortBy(lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_store = simple_Items_RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and Calculate length of Rating_vector\n",
    "1. map function construct_row_with_nornalization()進行Normalization, 主要步驟為先將平均值算出(sum of ratings / sum of rating user for that movie), 並進行去中心化，即將該movie 的ratings 減去平均數，並順便計算新的rating_vector的長度，最後return回去形成新的RDD，一樣以movie為id, 但values 是(user, sqrt(rating_vector_len))\n",
    "2. 附註: 在其中可能會出現去中心化後，所有rating都變為0的狀況，以此我的解決方法是之後將其filter刪除掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_row_with_nornalization(x):\n",
    "    part_list = list(x[1])\n",
    "    sum_ = 0\n",
    "    users = len(part_list)\n",
    "    for i in part_list:\n",
    "        sum_ += i[1]\n",
    "    mean = sum_/users\n",
    "    new_result = []\n",
    "    len_ = 0\n",
    "    cnt = 0\n",
    "    for j in part_list:\n",
    "        j = list(j)\n",
    "        user = int(j[0])\n",
    "        j[1] = j[1]-mean\n",
    "        len_+= j[1]**2\n",
    "        cnt+=1\n",
    "        new_result.append((user,j[1]))\n",
    "    #cal len\n",
    "    #if len_== 0:\n",
    "        #return x[0],(0,cnt,part_list) #(id,(len, mean, list))\n",
    "    return x[0],(math.sqrt(len_),new_result)\n",
    "Simple_Items_RDD = simple_Items_RDD.map(construct_row_with_nornalization).filter(lambda x:x[1][0]!=0).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t2 = Simple_Items_RDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Combination\n",
    "1. 為求出每個movie之間的相似度，我使用catesian進行組合，產生C(n,2) line數量的組合RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join\n",
    "cartesian_iten_item = Simple_Items_RDD.cartesian(Simple_Items_RDD).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cartesian_iten_item.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_items = cartesian_iten_item.filter(lambda x:((x[0][0]<x[1][0])))\\\n",
    "                                        .persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = combination_items.collect()\n",
    "#c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Cosine Similarity\n",
    "1. 有了上一步的結果，接下來就能開始計算相似程度\n",
    "2. 依據一組合出的line裡面提供的 movie_id, movie_vector, |movie|，可以直接利用公式: cosine = movie1 dot movie2/ |movie1|*|movie2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cal_similarity(x):\n",
    "    item1 = x[0][0]\n",
    "    s1 = x[0][1][0]\n",
    "    item2 = x[1][0]\n",
    "    s2 = x[1][1][0]\n",
    "    dividend = s1*s2\n",
    "    permutation = 0\n",
    "    for i in x[0][1][1]:\n",
    "        for j in x[1][1][1]:\n",
    "            if i[0]==j[0]:\n",
    "                permutation += i[1]*j[1]\n",
    "                break\n",
    "    try:\n",
    "        similarity = permutation/dividend\n",
    "    except:\n",
    "        result = ((item1,item2),0)\n",
    "        return result\n",
    "    result = (item1,item2),similarity\n",
    "    return result\n",
    "cos_sims = combination_items.map(cal_similarity).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t3 = cos_sims.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cos_sims.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t8 = cos_sims.collect()\n",
    "#t8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output To File\n",
    "1. 將結果利用 saveAsTextFile()，將結果output到out1的資料夾\n",
    "2. coalesce將RDD變成partition = 1的RDD，方便output時檔案不會變成分散式 \n",
    "3. 結果會在該資料夾內的part-00000檔案裡，\n",
    "4. 建議用Vscode打開，這樣才能做分配記憶體來開啟較大的檔案\n",
    "5. output pattern:\n",
    "### (item, item), similarity\n",
    "## 輸出結果為所有 \"可去中心化的\"  且  \"不同movies間\" 的相似度\n",
    "1. 附註: 為了demo呈現，以事先跑好output放在google雲端上sample_out資料夾的q1_similarity_part-00000.txt (雲端上已將副檔名改成.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cos_sims.coalesce(1,True).saveAsTextFile('out1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_Items_RDD.persist(StorageLevel.DISK_ONLY).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting The movie similarity\n",
    "1. 接下來要進行Prediction，我以item的叫角度出發，為了計算方便，可以利用map function duplicate 從 ((movie1,movie2),similarity) 額為複製出 ((movie2,movie1),similarity)的key value pair，並利用flatMap將他們拆開來。\n",
    "2. 下一步利用groupByKey將所有第一項相同的movie_id 聚集起來，形成一以movie_id為key, (other movie_id, similarity)為values的RDD\n",
    "3. 接下來為了之後的計算方便，我先利用map function sorting_list來進行每一個line內部values排序，依據similarity的大小來排序(由大到小)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting\n",
    "def duplicate(x):\n",
    "    m1 = x[0][0]\n",
    "    m2 = x[0][1]\n",
    "    sim = x[1]\n",
    "    ele1 = (m1,(m2,sim))\n",
    "    ele2 = (m2,(m1,sim))\n",
    "    return ele1,ele2\n",
    "def takeSecond(ele):\n",
    "    return ele[1]\n",
    "def sorting_list(x):\n",
    "    l = list(x[1])\n",
    "    l.sort(key=takeSecond, reverse=True)\n",
    "    return x[0],l\n",
    "item_sim = cos_sims.map(duplicate).flatMap(lambda x:x).groupByKey().map(sorting_list).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_sim.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ttmp = item_sim.collect()\n",
    "#ttmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get All Users\n",
    "1. 與第一步驟的做法雷同，只是這次要利用getNecesssary2()來建構以 user為key, (movie_id,rating)為values的RDD\n",
    "2. 利用 dict()來使查詢user rate的時候，以user_id為index，如此就不用刻意先sort好users RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_sim_table = item_sim.collect()\n",
    "#item_sim_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNecesssary2(x):\n",
    "    line = x.split(',')\n",
    "    user = str(line[0])\n",
    "    movie = str(line[1])\n",
    "    rating = float(line[2])\n",
    "    \n",
    "    pair = (movie, rating)\n",
    "    return user,pair\n",
    "users = sc.textFile(\"ml-latest-small/ratings.csv\").filter(lambda x:x[0]!='u').map(getNecesssary2).groupByKey()\\\n",
    "        .map(lambda x:(x[0],list(x[1])))\\\n",
    "        .persist(StorageLevel.DISK_ONLY)\n",
    "user_table = users.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_table = []\n",
    "for i in user_table:\n",
    "    tar = dict(i[1])\n",
    "    new_user_table.append((i[0],tar))\n",
    "new_user_table_dict = dict(new_user_table)\n",
    "#new_user_table_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caluclate all Prediction\n",
    "1. 有了user rated movie的資料後，以及movie間similarity的資料後，我們可以開始計算user評分其他為評分movie的rating了\n",
    "2. 在這我對movie_similarity的RDD進行map function cal_all_prediction()，在每個line裡進行610次的迴圈(user人數)，先檢查該user是否已經評分過該movie，若有，則換一下曾迴圈，反之，則進行prediction\n",
    "3. 在進行prediction時，先找出其他該user評分過且與目前movie相似度前10高的movie(不包括自己)\n",
    "4. 當找完10個後(或不滿10個)， 則可以開始利用加權平均的方式計算新的rating，權重為similarity，數值為rating\n",
    "5. 在function裡我利用try and except的方式來處理分母為0的情況\n",
    "6. 得出結果後，會append到一個負責收集該movie所有rating的list (all_rating)並在跑完迴圈後return，得出一(目前movie_id,user, rating)為element的新RDD\n",
    "7. 若是跑smaple.csv，可以將N=10改成N=2，這樣結果會與課本上的範例一樣，該結果一樣放在google雲端上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10\n",
    "users_num = users.count()\n",
    "def cal_all_prediction(x):\n",
    "    main_item = str(x[0])\n",
    "    all_rating = []\n",
    "    for i in range(users_num):\n",
    "        user_str = str(i+1)\n",
    "        try:\n",
    "            value = new_user_table_dict[user_str][main_item]\n",
    "            object_ = ((user_str,str(x[0])), value)\n",
    "            #all_rating.append(object_)\n",
    "            continue\n",
    "        except: # hasn't been rate\n",
    "            # find top N sim with main item\n",
    "            divider = 0\n",
    "            dividend = 0\n",
    "            cnt = 0\n",
    "            for i in x[1]:\n",
    "                if cnt==N: break\n",
    "                if i[1]>0:\n",
    "                    try:\n",
    "                        sim_one = str(i[0])\n",
    "                        rating = new_user_table_dict[user_str][sim_one] #user rate about sim_item\n",
    "                        dividend += rating*i[1]\n",
    "                        divider += i[1]\n",
    "                        cnt+=1\n",
    "                    except:\n",
    "                        continue\n",
    "            predict_rate = 0\n",
    "            try:\n",
    "                predict_rate = dividend/divider\n",
    "            except:\n",
    "                predict_rate = 0\n",
    "            object_ = ((int(user_str),int(x[0])), predict_rate)\n",
    "            all_rating.append(object_) \n",
    "    return all_rating\n",
    "ans3 = item_sim.map(cal_all_prediction).persist(StorageLevel.DISK_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp3 = ans3.flatMap(lambda x:x).filter(lambda x:x[2]>0).collect()\n",
    "#tmp3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output To File\n",
    "1. 利用coalesce，將RDD repatition成1 partition的RDD，並利用flatMap來取的所有elements，並利用saveAsFile來output資料至out2的資料夾\n",
    "2. 結果將存到out2資料夾內 part-00000檔案內，一樣建議用VsCode打開\n",
    "3. output pattern:\n",
    "### (user, item), rating)\n",
    "## 輸出結果為所有 \"可被預測的\" 且 \"預測值大於0的\" user rating\n",
    "4. 附註: 為了demo呈現，以事先跑好output放在google雲端sample_out資料夾的q2_prediction_part-00000.txt (雲端上已將副檔名改成.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3.coalesce(1,True).flatMap(lambda x:x).filter(lambda x:x[1]>0).filter(lambda x:x[1]>0).saveAsTextFile('out2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ans3.coalesce(1,True).flatMap(lambda x:x).sortBy(lambda x: (x[0][0], x[0][1])).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
